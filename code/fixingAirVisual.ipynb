{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leqJMYGJhNcH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mxnet import gluon, autograd, init, nd\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as mx\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('4cvxlkt', 'aishamanzil', 'Karachi')\n",
      "('4ypxth4', 'Defence Housing Authority', 'Karachi')\n",
      "('997gv7h', 'northkarachi', 'Karachi')\n",
      "('a67pmak', 'landhi', 'Karachi')\n",
      "('aj9xpaw', 'Korangi', 'Karachi')\n",
      "('ajgclt7', 'Korangi (J-Area)', 'Karachi')\n",
      "('awawxwx', 'Fida Hussain House, Bedian Road', 'Lahore')\n",
      "('cpguxuc', 'saddar', 'Karachi')\n",
      "('crp4y7m', 'Peshawar Node', 'Peshawar')\n",
      "('g6gs9ls', 'Hyderi Market', 'Karachi')\n",
      "('kuh6xuc', 'Lahore Cantt', 'Lahore')\n",
      "('kxvyx76', 'Lahore (Upper Mall)', 'Lahore')\n",
      "('lllm4gm', 'bahadurabad', 'Karachi')\n",
      "('lwpu64p', 'orangi town', 'Karachi')\n",
      "('m9cuxv7', 'd.h.a phase 5', 'Karachi')\n",
      "('rjpamt6', 'karachi - industrial', 'Karachi')\n",
      "('sarpstt', 'Al Farooq School', 'Bahawalpur')\n",
      "('tj4gawm', 'shershah', 'Karachi')\n",
      "('tlxa6x7', 'Liaquatabad', 'Karachi')\n",
      "('twa67s6', 'mt khan road', 'Karachi')\n",
      "('u7cwkla', 'Sector E11', 'Islamabad')\n",
      "('yggpgpl', 'Civic Center, Korangi', 'Karachi')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151256"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfraw = pd.read_csv('../data/FinalData.csv')\n",
    "\n",
    "dfgp = dfraw.groupby(['SerialNumber', 'Name', 'City'])\n",
    "for i,k in dfgp:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "dfc = dfraw.drop_duplicates()\n",
    "assert len(dfc) == len(dfraw)\n",
    "len(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SerialNumber', 'City', 'Name', 'FirstOnline', 'Datetime', 'PM2.5',\n",
       "       'USAQI', 'CO2', 'Temperature', 'RelativeHumidity', 'Outdoor PM2.5',\n",
       "       'OutdoorUSAQI', 'weekday', 'weekdayName', 'hour', 'month', 'year',\n",
       "       'dayofmonth', 'tmpc', 'relh', 'drct', 'sped', 'vsby'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['City', 'Name', 'FirstOnline', 'Outdoor PM2.5', 'OutdoorUSAQI', 'weekdayName']\n",
    "df = dfc.drop(drop_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SerialNumber         9.891178\n",
       "Datetime             0.000000\n",
       "PM2.5                0.000000\n",
       "USAQI                0.000000\n",
       "CO2                  9.891178\n",
       "Temperature          0.991035\n",
       "RelativeHumidity     0.991035\n",
       "weekday              0.000000\n",
       "hour                 0.000000\n",
       "month                0.000000\n",
       "year                 0.000000\n",
       "dayofmonth           0.000000\n",
       "tmpc                22.101603\n",
       "relh                22.483736\n",
       "drct                22.043423\n",
       "sped                21.995161\n",
       "vsby                21.975327\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-8406bdd05f5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdfgp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SerialNumber'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'City'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfgp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   7892\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7893\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7894\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7895\u001b[0m         )\n\u001b[0;32m   7896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2520\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             )\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "df= df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df.Datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.sort_values(['SerialNumber', 'Datetime'])\n",
    "dfs = dfs.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_many_to_one(dataframe, time_steps):\n",
    "    rows = dataframe.shape[0] - time_steps\n",
    "    cols = dataframe.shape[1]\n",
    "    dfnew = nd.zeros(shape = (rows, cols * time_steps))\n",
    "    for i in range(0, time_steps):\n",
    "        dfnew[:, i * cols : (i + 1 ) * cols] = dataframe.iloc[i: i + rows,:]\n",
    "    ynew = nd.zeros(shape = (rows, 1))\n",
    "    ynew[:,0] = dataframe['PM2.5'].iloc[time_steps:]\n",
    "    return dfnew, ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def myPartSerial(i, time_steps):\n",
    "    dfslice = dfs[dfs.SerialNumber == i]\n",
    "    lis = []\n",
    "        \n",
    "    dfdiff = dfslice.Datetime.diff()\n",
    "    dfdiff.iloc[0] = dfdiff.iloc[1]\n",
    "    dfdiff2 = dfdiff != pd.Timedelta('1 hour')\n",
    "    dfdiff3 = dfdiff2.cumsum()    \n",
    "    \n",
    "    for j,k in dfslice.groupby(dfdiff3):\n",
    "        if len(k) > time_steps:\n",
    "            d = k.iloc[:]\n",
    "            drop_columns2 = ['SerialNumber', 'Datetime', 'year', 'relh', 'tmpc']\n",
    "            d = d.drop(drop_columns2, axis = 1)\n",
    "            lis.append( d )\n",
    "    \n",
    "    newlis = []\n",
    "    newlabels = []\n",
    "    for i in lis:\n",
    "        a, b = make_dataset_many_to_one(i, time_steps)\n",
    "        assert a.shape[0] == b.shape[0]\n",
    "        newlis.append(a)\n",
    "        newlabels.append(b)\n",
    "    \n",
    " \n",
    "    newlis = nd.concatenate(newlis)\n",
    "    newlabels = nd.concatenate(newlabels)\n",
    "#    newlis = nd.array(newlis)\n",
    "#    print(newlist.shape)\n",
    "    \n",
    "    \n",
    "    return newlis, newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SerialNumber</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>USAQI</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RelativeHumidity</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>tmpc</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sped</th>\n",
       "      <th>vsby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4cvxlkt</td>\n",
       "      <td>2018-01-03 00:00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137</td>\n",
       "      <td>471.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>68.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4cvxlkt</td>\n",
       "      <td>2018-01-03 01:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>122</td>\n",
       "      <td>483.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.09</td>\n",
       "      <td>235.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4cvxlkt</td>\n",
       "      <td>2018-01-03 02:00:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>132</td>\n",
       "      <td>422.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>68.55</td>\n",
       "      <td>260.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4cvxlkt</td>\n",
       "      <td>2018-01-03 03:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>122</td>\n",
       "      <td>408.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>64.48</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4cvxlkt</td>\n",
       "      <td>2018-01-03 04:00:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>132</td>\n",
       "      <td>420.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>59.25</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SerialNumber            Datetime  PM2.5  USAQI    CO2  Temperature  \\\n",
       "0      4cvxlkt 2018-01-03 00:00:00   50.0    137  471.0         27.0   \n",
       "1      4cvxlkt 2018-01-03 01:00:00   44.0    122  483.0         27.0   \n",
       "2      4cvxlkt 2018-01-03 02:00:00   48.0    132  422.0         27.0   \n",
       "3      4cvxlkt 2018-01-03 03:00:00   44.0    122  408.0         26.0   \n",
       "4      4cvxlkt 2018-01-03 04:00:00   48.0    132  420.0         26.0   \n",
       "\n",
       "   RelativeHumidity  weekday  hour  month  year  dayofmonth  tmpc   relh  \\\n",
       "0              64.0        3     0      3  2018           1  21.0  68.55   \n",
       "1              64.0        3     1      3  2018           1  21.0  73.09   \n",
       "2              61.0        3     2      3  2018           1  21.0  68.55   \n",
       "3              61.0        3     3      3  2018           1  22.0  64.48   \n",
       "4              62.0        3     4      3  2018           1  25.0  59.25   \n",
       "\n",
       "    drct  sped  vsby  \n",
       "0  230.0  4.60  3.73  \n",
       "1  235.0  4.60  3.73  \n",
       "2  260.0  5.75  3.42  \n",
       "3  125.0  2.30  2.49  \n",
       "4  125.0  2.30  2.49  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90666, 48)\n",
      "(90666, 1)\n"
     ]
    }
   ],
   "source": [
    "lis = []\n",
    "labelslis = []\n",
    "time_step = 4\n",
    "\n",
    "for i in dfs.SerialNumber.unique()[:]:\n",
    "    li, la = myPartSerial(i, time_step)\n",
    "    lis.append(li)\n",
    "    labelslis.append(la)\n",
    "    \n",
    "lis = nd.concatenate(lis)\n",
    "labelslis = nd.concatenate(labelslis)\n",
    "\n",
    "print(lis.shape)\n",
    "print(labelslis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.3\n",
    "col_count = lis.shape[1] / time_step\n",
    "assert col_count == int(col_count)\n",
    "col_count = int(col_count)\n",
    "\n",
    "train_count = int((1 - test_ratio) * lis.shape[0])\n",
    "train_count = train_count // col_count * col_count\n",
    "\n",
    "train_x = lis[:train_count]\n",
    "total_x = lis[:]\n",
    "\n",
    "trn_x = train_x.reshape(-1, time_step, col_count)\n",
    "tot_x = total_x.reshape(-1, time_step, col_count)\n",
    "trn_y = labelslis[:train_count].reshape(-1)\n",
    "tot_y = labelslis[:].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            \n",
    "            self.lstm = gluon.rnn.LSTM(120,1,dropout=0.2)\n",
    "            self.out = gluon.nn.Dense(1)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.lstm(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = mx.io.NDArrayIter(trn_x, trn_y, batch_size, shuffle=True)\n",
    "device = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "net.initialize(force_reinit=True,  init=init.Xavier(), ctx=device)\n",
    "loss = gluon.loss.L2Loss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eva(net, X, y, l, plot = False):\n",
    "    y_hat = net(X)\n",
    "    if plot:\n",
    "        for i in range(0, min(len(y), 150), 50):\n",
    "            plt.plot(y[i : i+50].asnumpy())\n",
    "            plt.plot(y_hat[i : i+50].asnumpy())\n",
    "            plt.show()\n",
    "\n",
    "    return l(y_hat, y).mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for trn_batch in train_iter:\n",
    "\n",
    "        X = trn_batch.data[0].as_in_context(device)\n",
    "        y = trn_batch.label[0].as_in_context(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        with autograd.record():\n",
    "            y_pred = net(X)\n",
    "            l = loss(y_pred, y)\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        trainer.step(batch_size = batch_size)\n",
    "    \n",
    "    train_iter.reset()\n",
    "    \n",
    "    print('epoch number ', epoch)\n",
    "    print(\"traingin data loss\\t\", eva(net, trn_x.as_in_context(device), trn_y, loss) )\n",
    "    print(\"testing data loss\\t\", eva(net, tot_x.as_in_context(device), tot_y, loss) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ann.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
